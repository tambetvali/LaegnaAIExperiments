# Purpose and format of components

We divide this AI forum into it's subcomponents, which have intents:
- They are clearly described, documented, and outside the scope of local conversation, which are lost to poorly indexed history pages, and often forgotten in code and docs unless issues are mentioned as sources (work basis) and references (reuse basis).
- They form an API: a roughly one-page introduction. An AI can do analysis on multiple of such pages at once, so we can create tasks.
- They have unique identifier: their URL is provided by github.com domain server, and encoded by github, this is fairly enough in technical purpose to gain one unique id, and to access a specific document by it's name and location.
  - We give an AI short task in our manual and implementation, but it will be based on this API and filenames and location, which are essential assets in our thinking: how our AI scripts, use cases, and combined materials include those sources.
  - To simulate source access, we can study the XML tags or other internal codes, such as internal tokens we can not use in the text and body of the tags, available as API variables of this Q&A.
  - Remember: if we use Q&A so often, for machine learning to assign equation variables into input and output, which form Q&A in code processing, and in Q&A for chatgpt and many image, video or other type of processing systems: like machine learning, they have some wizardly aspect to have structures of those formats, and perhaps some graphical visualizers or accessors.
  - Q&A can be complified to a class:
    - API variables, each appears in Q where the function or method is given some input.
    - In fine-tuning and training, the function or method with it's input is assigned a value, and the optimizer is iterated slightly towards preferring such value in a combination (a partial logic operation, sligh process towards logic, but only approaching local logic in each single case: evolution is doing the magic witchcraft to suddenly provide some fit species, and we be feared of the leaves which should actually become extinct, if our optimizer strategy is not well fit to larger scale - this comes from data, which might not linearize well even in multidimensional spaces with activators; for this we use many billions of parameters on evolving system, which can satisfy this).
- We need intuitions of AI for optimization: the simple guide of an AI is better than complex architecture, because whatever the architecture is, it's essentially doing iterative optimization of continuous, higher matrix space and repetitive matrix space, simulating a number of subsequent time items where each new time step or layer means the next shell of knowledge is applied on the result; backgradient is the effect-and-cause, which brings an oracle estimator back from chain: the chain which is evolutionarly most capable, has the spirit to flow towards the future, which is the magic where we do not want to use rational mind, but rather a large matrix of complex dimension.
- Where rational, single-equation or expressible solutions exist, we can do our personal wizardly and magic for others: humans working on data are very efficient, and simple data tables can be processed where we enter our equations, equation sets, handmade algorithms and compare the estimation with result, optimizing the estimation basis and hoping our determinant is oraculous, somehow determined by common cause rather than randomization towards our decidable solution space of the real and experienced past.
  - AI experience is how you feed the Q&A cards.
  - It is verified by cards you have not yet fed, and for the last card it's not a big deal: it's a small variation.
    - In such algorithm, you must detect the metavariables you can optimize, early, and verify in the prominent failure or ultimate success of the final process: does it remain oraculous in this estimation.

The specification: in this API ==> Spec division, use of API leads to production due to it's specification.

Specification gives you:
- Details of this task is the manual form. For future enchange of an AI, it's important that it meets and keeps up this specification: most annoying thing if it removes old features if they do not fit the new task easily, you must somewhat document the changes and update the document files.
- Explanation of code is the documentation form.
- Finally, in the specification you have code files and examples, which allow to build the final part of the product.

# Simplification

With an AI, we need to be fools: nothing big must happen.

Each user interface element must be small, and use existing features and libraries as much as possible: this is critical and profound truth of the programming.
- The AI, actually, wants to implement things you can describe in 2-6 lines, altough it can use a lot of additional information.
- Use less memory for subcomponents to ensure their public APIs are trivially implied by specification, and cover it's essential details which can be trained in AI pattern tracks. Let's think in the box.

Each encapsulating element must be general enough:
- "General": this means it's small, but not towards details but towards their essential, practical and usable aspects which define the products.
- AI is trained on human common sense, and thus the simplification is not merely an artificial thing: you *really* seem to make things trivial; things which have patterns, tracks and habit guides, do not bring any complexity, which is resolved in the common habit; you can also see an AI is able to take these patterns to metastates, and induce a big deal of innovation and creativity in addition to this productivity: but even this, if you speak in general terms.
- This has general summary, and it's specification or body will include summaries and references to the parts: you can bring a single XML tag, which will bring both summaries and references to conciousness of an AI, while you give only the reference with tag.

For example, a Tag:

```
%#(/Reference)#%www.google.com%#(Reference/)#%
```

This single reference:
- Rather than HTML tags, which are very complex by having many elements inside a tag: these attributes I mark in this format are very expressible, and allow creating things which look rather like common forms, filled forms and templates or examples, than very cryptic syntax.

This is crypic:
```
<reference
    escapedHTMLContent="www.google.com"
>
```

Because we are common users and data scientists, and we are curious and careful about each data event, and talk seriously about them: programmers might think in advanced ways to throw millions of these elements into their code and it's implications and output previews, so they look like primitives of a complex, rather than separate, honorous members of information space we more or less manually update and control.

HTML tag's attribute, as well, is not either normal text, based on non-parsing and often custom work before processing of Markdown, based on our file format, is not very good: it's rather an escaped text sequence which cannot contain all HTML, including normal line feeds and security and non-escaped characters. So the "Attributes" in markup languages are often for advanced use, while our attribute tags look like simple html: like <i> and <b>, where BBCode was not so nice to use and easy to watch - but most users would tolerate if it's used for complex, strict parsable elements rather than native formatting alone; Markdown replaced BBCode in most places where it was used, or it's analogies, but using such complex things like boxes and circles to mark fields in forms: is more common in text, and most people draw boxes around these elements, or use box- and circle-like characters.

What I mean by this complexity? The form fields are where most humans start to do variable-processing kind of things, and they understand that whole fields can have different values based on instances; so they find class and table-row or it's schema-field structures relatively easy, even global variables in forms about metasciences and general facts. I do not think they find variables inside sentences easy, or apply this logic on each word in a sentence, or list of words: they rather expect at least bullets and new paragraphs to process lists. So this complexity syndrome rather applies that we do not put higher complexity to smaller elements of text, if the piece itself is at AI- or "spirit-"complexity, because this small level is rather crossword-complexity, where we really do heavy magic and something we don't rationally express based on dictionary use. Definition and it's name is well linked in dictionaries, discussions, etc., but we can see they are *not easy if expressed in the same sentence*, which is kind of metalinguistic fact I utilize in this kind of syntaxes in my examples and experiments, rather than pure XML which would suffice and be used by standards in Markdown: in case you are programming a large system with many small variables inside, rather than meaningful, contextual and important elements: indeed, try XML, or Prolog syntax as well, but I think it's for different means you can apply in supported code and binary files and use with tool extensions, if you work in this scope.

Well I hope you like heavy philosophy: but to give you these tags and say what they mean in my popular, mainstream, but also useful and evolved into spirit from this machinelike thinking I used in programming beforehands: with some AI use, the conceptions are rather defined by meaningful sentence, and your spirit moves form mere patterns to recognize, where before, you added many "attributes" and used heavy scientific words about attribute-like things like properties, to match exact math definition. Now it's nice to use these math definitions for aspects and particulars, but you don't follow rigid structure: you use the same data to regenerate new structures, and the chaotic data is structured on particulars and their matter basis.

To form large, interconnected, rigid yet scientific and practical structures:
- Do not follow IBM because inside, they must really do some dangerous magic to achieve this. Normal people will be burnt in hell if they want a specification which is 50 billion lines long, but they can have conversations on these topics which just *seem* to form this complexity once you *really* want to write it down for the generations to use without change of schema and structure, classes and templates.
- If you used to create operating systems and things like Lotus Notes, programming them yourself or with your company: maybe in each kind of documentation, you can really do it but only in case you think it's something very specific about an operating system for others, in area where you really need regulations. Sometimes, AI would still outperform you in the long run.
- You could easily go mad if data is rotating through endless forms and never stating that a particular form is a definite, ideal true space where you want to project your ideas and variables. Achieving something definite, common to use, without many hours of discussions, specifications, even blame and some form of politics: you rather find that particular lists, mind maps and local orders of your data, structures into creative chapter trees which follow only vague guidelines and some assertness, you can slowly find out you have written it down, and others can really succeed even if they did not get *every detail* in strictly formatted table, which is what you won't easily get for particular events and details - this is like the car type playing cards, where each car is described in 6 parameters and you ask for one to compare, when it's your turn; cars are really more complicated, and their architectures less structured in real world - IBM, really, will count all the cars and magically agree with your own self-made design as something typical to this or that; but you probably need some kind of unstructured set of notes about cars, to be able to say anything at all.
- This rules *did not hold when rigid data was inevitable*, and dictatorship-like structures where you cannot meaningfully discuss the intent of database creator or official, can still apply if you need very rigid process; it's not so dictator if the variables *really* are that meaningful in this particular case, such as how far a runner did run if you are interested in selecting on this particular variable - you might still have free-form semantics and some creative touch if you want to choose runner for movie with low level of effects.
